{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpctGiM+k/f+PdFs/wrPxy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xc-ZWsi66tGk"
      },
      "outputs": [],
      "source": [
        "# Building a binary classifier using Neural Networks.\n",
        "# We are classifying loan approval or disapproval based on the features like:\n",
        "# - Income of Customer\n",
        "# - Credit Score\n",
        "# - Years of experience of a customer\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TensorFlow warnings\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential, layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input features - input to neural network.\n",
        "X = np.array([\n",
        "  [45000, 650, 5],\n",
        "  [75000, 720, 10],\n",
        "  [30000, 580, 2],\n",
        "  [90000, 780, 15],\n",
        "  [50000, 620, 3]\n",
        "])"
      ],
      "metadata": {
        "id": "sc8IF0nD7k_n"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual output labels (1 for approved, 0 for disapproved).\n",
        "# Correct labels for learning.\n",
        "Y = np.array([1, 1, 0, 1, 0])"
      ],
      "metadata": {
        "id": "CIJXFy_7LiF2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building neural network architecture.\n",
        "model = Sequential([\n",
        "  layers.Input(shape=(3,)),  # Input layer - fixes the warning\n",
        "  layers.Dense(3, activation='relu'),  # Hidden layer with 3 neurons and ReLU activation.\n",
        "  layers.Dense(3, activation='relu'),  # Hidden layer with 3 neurons and ReLU activation.\n",
        "  layers.Dense(3, activation='tanh'),  # Hidden layer with 3 neurons and Tanh activation.\n",
        "  layers.Dense(1, activation='sigmoid')  # Output layer with 1 neuron and sigmoid activation for binary classification.\n",
        "])\n",
        "\n",
        "model.summary()  # Print the model summary to check the architecture."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "hxfRv_baLnWt",
        "outputId": "4b4bef9c-6a95-4cca-aad1-e792179023f9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m12\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m12\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m12\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m4\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40\u001b[0m (160.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> (160.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40\u001b[0m (160.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> (160.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In output shape or summary `None` means that the model can accept any number of samples (rows) in the input data, while 3 means that each sample has 3 features (columns). This allows the model to be flexible and work with different batch sizes during training and inference.\n",
        "\n",
        "# ============================================================================\n",
        "# PARAMETER CALCULATION FORMULA\n",
        "# ============================================================================\n",
        "# Number of parameters = (Number of input features × Number of neurons) + Number of neurons\n",
        "#                      = Weights                                        + Biases\n",
        "#\n",
        "# VISUAL EXPLANATION:\n",
        "#\n",
        "# Example: Input layer (3 features) → First hidden layer (3 neurons)\n",
        "#\n",
        "# Input (3)          Hidden Layer (3 neurons)\n",
        "#\n",
        "# x1 ─────w11─────→ neuron1 + b1\n",
        "#    \\    w12─────→ neuron2 + b2\n",
        "#     \\   w13─────→ neuron3 + b3\n",
        "#      \\\n",
        "# x2 ──\\──w21─────→ neuron1\n",
        "#       \\ w22─────→ neuron2\n",
        "#        \\w23─────→ neuron3\n",
        "#         \\\n",
        "# x3 ─────w31─────→ neuron1\n",
        "#         w32─────→ neuron2\n",
        "#         w33─────→ neuron3\n",
        "#\n",
        "# Weights: 9 (w11, w12, w13, w21, w22, w23, w31, w32, w33)\n",
        "# Biases:  3 (b1, b2, b3) - ONE bias per neuron\n",
        "# Total:   12 parameters\n",
        "#\n",
        "# Calculation: (3 inputs × 3 neurons) + 3 biases = 9 + 3 = 12\n",
        "# ============================================================================"
      ],
      "metadata": {
        "id": "KntvJK_gLt2S"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}
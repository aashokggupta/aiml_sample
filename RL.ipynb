{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwmcHil-YoF3",
        "outputId": "96ad299e-422a-4491-8c2a-7be5d7b59a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import imageio\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "print(\"loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "value iteration\n",
        "high level\n",
        "1. start with V(s) = 0 for every state\n",
        "2. repeat sweeps/iterations for all states\n",
        "       for each state s, look at every action a\n",
        "       for each action, sum over every possible next-state s' using the known trans prob's P(s'|s,a)to compute\n",
        "       expected value of taking that actions\n",
        "       set V(s) = max over all the actions\n",
        "3. stop when the largest change across all states (delta) is tiny\n",
        "4. extract greedy policy  pi(s) = argmax_a V(s,a)\n",
        "\n",
        "\"\"\"\n",
        "def value_iteration(env, discount=0.99, theta=1e-6, max_iters=5000):\n",
        "  n_states = env.observation_space.n # 16 fro 4x4 grid\n",
        "  n_actions = env.action_space.n # 4 {0: '←', 1: '↓', 2: '→', 3: '↑'}\n",
        "\n",
        "  # transition model\n",
        "  # P[ice][right] = (0.7, 'hole', -20, done=true)\n",
        "  # P[s][a] is a list of (prob, next_state, reward, done) tuples\n",
        "\n",
        "  P = env.unwrapped.P\n",
        "\n",
        "  V = np.zeros(n_states)\n",
        "\n",
        "  for it in range(max_iters):\n",
        "    delta = 0.0\n",
        "\n",
        "    for s in range(n_states):\n",
        "      v_vals = []\n",
        "      for a in range(n_actions):\n",
        "        v = 0.0\n",
        "        for prob, next_s, reward, done in P[s][a]:\n",
        "          v += prob * (reward + discount * V[next_s] * (not done))\n",
        "        v_vals.append(v)\n",
        "\n",
        "      best = max(v_vals)\n",
        "\n",
        "      delta = max(delta, abs(best-V[s]))\n",
        "      V[s] = best\n",
        "\n",
        "    if delta < theta:\n",
        "      print(\"converged in sweeps\")\n",
        "      break\n",
        "\n",
        "  policy = np.zeros(n_states, dtype=int)\n",
        "  for s in range(n_states):\n",
        "    v_vals = []\n",
        "    for a in range(n_actions):\n",
        "      v = 0.0\n",
        "      for prob, next_s, reward, done in P[s][a]:\n",
        "        v += prob * (reward + discount * V[next_s] * (not done))\n",
        "      v_vals.append(v)\n",
        "      policy[s] = int(np.argmax(v_vals)) # best action index\n",
        "\n",
        "  return V, policy\n",
        "\n",
        "  print(\"value itr complete\")\n"
      ],
      "metadata": {
        "id": "wXJB-GESZPRl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake-v1', map_name='4x4', is_slippery=True)\n",
        "\n",
        "V_opt, policy_opt = value_iteration(env, discount=0.99, theta=1e-8)\n",
        "\n",
        "action_map = {0: '←', 1: '↓', 2: '→', 3: '↑'}\n",
        "for s in range(env.observation_space.n):\n",
        "  arrow = action_map[policy_opt[s]]\n",
        "  print(f\"State {s:2d}: {arrow}\")\n",
        "\n",
        "def run_policy(policy, episodes=30, max_steps=100):\n",
        "  wins = 0\n",
        "  for _ in range(episodes):\n",
        "    state = env.reset()\n",
        "    if isinstance(state, tuple):\n",
        "      state = state[0]\n",
        "    done = False\n",
        "    steps = 0\n",
        "    while not done and steps < max_steps:\n",
        "      action = policy[state]\n",
        "      state, reward, terminated, truncated, _ = env.step(action)\n",
        "      done = terminated or truncated\n",
        "      steps +=1\n",
        "      if reward > 0:\n",
        "        wins+=1\n",
        "        break\n",
        "  return wins / episodes\n",
        "\n",
        "sucess_rate = run_policy(policy_opt, episodes=200)\n",
        "print(f\"\\nSuccess rate over 200 eval episodes: {sucess_rate*100:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HwWRT1ef0Ri",
        "outputId": "2900fa1a-936f-43fe-db83-b09ea5cde186"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "converged in sweeps\n",
            "State  0: ←\n",
            "State  1: ↑\n",
            "State  2: ↑\n",
            "State  3: ↑\n",
            "State  4: ←\n",
            "State  5: ←\n",
            "State  6: ←\n",
            "State  7: ←\n",
            "State  8: ↑\n",
            "State  9: ↓\n",
            "State 10: ←\n",
            "State 11: ←\n",
            "State 12: ←\n",
            "State 13: →\n",
            "State 14: ↓\n",
            "State 15: ←\n",
            "\n",
            "Success rate over 200 eval episodes: 71.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_grid_img(env, state, size=400):\n",
        "  nrow, ncol = env.unwrapped.desc.shape\n",
        "  cell_size = size // max(nrow, ncol)\n",
        "\n",
        "\n",
        "  img = Image.new('RGB', (ncol * cell_size, nrow * cell_size), 'white')\n",
        "  draw = ImageDraw.Draw(img)\n",
        "\n",
        "  colors = {\n",
        "\n",
        "            b'S':(144, 238, 144),\n",
        "            b'F':(175, 216, 230),\n",
        "            b'H':(105, 105, 105),\n",
        "            b'G':(255, 215, 0)\n",
        "  }\n",
        "\n",
        "  for i in range(nrow):\n",
        "    for j in range(ncol):\n",
        "      cell = env.unwrapped.desc[i][j]\n",
        "      color = colors.get(cell, (255, 255, 255))\n",
        "      x1, y1 = j * cell_size, i * cell_size\n",
        "      x2, y2 = x1 + cell_size, y1 + cell_size\n",
        "      draw.rectangle([x1, y1, x2, y2], fill=color, outline='black', width=3)\n",
        "\n",
        "      label = 'START' if cell == b'S' else 'GOAL' if cell == b'G' else 'HOLE' if cell == b'H' else ''\n",
        "      if label:\n",
        "        bbox = draw.textbbox((0, 0), label)\n",
        "        tw, th = bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
        "        draw.text((x1 + (cell_size - tw) // 2, y1 + (cell_size - th) // 2), label, fill='black')\n",
        "\n",
        "\n",
        "  row, col = divmod(state, ncol)\n",
        "  cx = col * cell_size + cell_size // 2\n",
        "  cy = row * cell_size + cell_size // 2\n",
        "  r =  cell_size // 4\n",
        "  draw.ellipse([cx - r, cy - r, cx + r, cy+r], fill='red', outline='black', width=3)\n",
        "\n",
        "  return np.array(img)\n",
        "\n",
        "def record_policy_episode(env, policy, max_steps=100):\n",
        "  frames = []\n",
        "\n",
        "  state = env.reset()\n",
        "  if isinstance(state, tuple):\n",
        "    state = state[0]\n",
        "  frames.append(create_grid_img(env, state))\n",
        "\n",
        "  done = False\n",
        "  steps = 0\n",
        "  reached, hole = False, False\n",
        "\n",
        "  while not done and steps <max_steps:\n",
        "    action = policy[state]\n",
        "    state, reward, terminated, truncated, _ = env.step(action)\n",
        "    done = terminated or truncated\n",
        "    frames.append(create_grid_img(env, state))\n",
        "    steps +=1\n",
        "\n",
        "    if done:\n",
        "      if reward > 0:\n",
        "        reached = True\n",
        "      else:\n",
        "        hole = True\n",
        "      for _ in range(5):\n",
        "        frames.append(frames[-1])\n",
        "      break\n",
        "  return frames, steps, reached, hole\n",
        "\n",
        "frames_dp, steps_dp, reached_dp, hole_dp = record_policy_episode(env, policy_opt)"
      ],
      "metadata": {
        "id": "9fZw-VBtid34"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_gif(frames, filename, text, steps, reached_goal, fell_in_hole):\n",
        "  font = ImageFont.load_default()\n",
        "  processed = []\n",
        "\n",
        "  for i, frame in enumerate(frames):\n",
        "    img = Image.fromarray(frame)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    stat = 'REACHED GOAL!' if reached_goal else 'FELL IN HOLE' if fell_in_hole else f'Step {i}/steps'\n",
        "    title = f\"{text}\\n{stat}\"\n",
        "\n",
        "    y = 10\n",
        "\n",
        "    for line in title.split('\\n'):\n",
        "      bbox = draw.textbbox((0, 0), line, font=font)\n",
        "      tx = (img.width - (bbox[2]-bbox[0])) // 2\n",
        "      draw.text((tx, y), line, fill='black', font=font)\n",
        "      y += bbox[3] - bbox[1] +4\n",
        "\n",
        "    processed.append(np.array(img))\n",
        "\n",
        "  imageio.mimsave(filename, processed, fps=5, loop=1)\n",
        "  print(\"saved file\")\n",
        "\n",
        "create_gif(frames_dp, 'froz.gif', 'DP frozen lake', steps_dp, reached_dp, hole_dp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSiK3qd7meuX",
        "outputId": "92447167-0152-4315-bb51-e095fda44e6f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved file\n"
          ]
        }
      ]
    }
  ]
}